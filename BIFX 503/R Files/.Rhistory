library(MASS)
?Pima.tr
summary(Pima.tr)
head(Pima.tr)
glm(type ~ npreg, data = Pima.tr, family = binomial())
mod_npreg <- glm(type ~ npreg, data = Pima.tr, family = binomial())
View(mod_npreg)
summary(mod_npreg)
exp(coef(mod_npreg))
exp(confint(mod_npreg))
exp(confint(glm(type ~ npreg, data = Pima.tr, family = binomial()))) # Confidence Intercal
glm(type ~ npreg, data = Pima.tr, family = binomial()) #P-Value
summary(mod_npreg)
exp(coef(mod_npreg))
exp(confint(mod_npreg))
summary(mod_npreg)
mod_bp <- glm(type ~ bp, data = Pima.tr, family = binomial())
summary(mod_bp)
exp(coef(mod_bp))
exp(confint(mod_bp))
library(MASS)
mod_skin <- glm(type ~ skin, data = Pima.tr, family = binomial())
summary(mod_skin)      # P-Value
exp(coef(mod_skin))    # Exponentiated Coefficient
exp(confint(mod_skin)) # Exponentiated Confidence Interval
mod_bmi <- glm(type ~ bmi, data = Pima.tr, family = binomial()) # Fit
summary(mod_bmi)      # P-Value
exp(coef(mod_bmi))    # Exponentiated Coefficient
exp(confint(mod_bmi)) # Exponentiated Confidence Interval
mod_age <- glm(type ~ age, data = Pima.tr, family = binomial()) # Fit
summary(mod_age)      # P-Value
exp(coef(mod_age))    # Exponentiated Coefficient
exp(confint(mod_age)) # Exponentiated Confidence Interval
fit_a <- glm(type ~ age + bmi, data = Pima.tr, family = binomial())
fit_b <- glm(type ~ age + npreg, data = Pima.tr, family = binomial())
fit_c <- glm(type ~ age + skin, data = Pima.tr, family = binomial())
fit_d <- glm(type ~ age + bp, data = Pima.tr, family = binomial())
anova(mod_age, fit_a)
anova(mod_age, fit_b)
anova(mod_age, fit_c)
anova(mod_age, fit_d)
fit1 <- lm(Price ~ Horsepower, Cars93)
fit2 <- lm(Price ~ Horsepower + MPG.average, Cars93)
fit3 <- lm(Price ~ Horsepower + AirBags, Cars93)
anova(fit1, fit3)
anova(mod_age, fit_a)
summary(mod_age)      # P-Value
summary(fit_a)
anova(mod_age, fit_a, test="Chisq")
anova(mod_age, fit_b, test="Chisq")
anova(mod_age, fit_c, test="Chisq")
anova(mod_age, fit_d, test="Chisq")
mod_final <- glm(type ~ age + bmi + skin, data = Pima.tr, family = binomial())
exp(coef(mod_final))
exp(confint(mod_final))
head(Pima.tr)
logpred2 <- predict(mod_final, type="response", title = "Age + BMI + Skin")
roccurve2 <- roc(Pima.tr$age ~ logpred2)
roccurve2  ## AUC = 0.81
plot(roccurve2)
library(pROC)
logpred2 <- predict(mod_final, type="response", title = "Age + BMI + Skin")
roccurve2 <- roc(Pima.tr$age ~ logpred2)
roccurve2  ## AUC = 0.81
plot(roccurve2)
par(mfrow=c(1,2))
logpred1 <- predict(mod_age, type="response")
roccurve1 <- roc(Pima.tr$type ~ logpred1, title = "Age (Alone)")
roccurve1  ## AUC = 0.71
plot(roccurve1)
logpred2 <- predict(mod_final, type="response", title = "Age + BMI + Skin")
roccurve2 <- roc(Pima.tr$type ~ logpred2)
roccurve2  ## AUC = 0.81
plot(roccurve2)
par(mfrow=c(1,1))
pima_rpart <- rpart(type ~ age + bmi + npreg + skin + bp, data = Pima.tr, control = rpart.control(minsplit=10))
plot(as.party(Pima.tr_rpart), tp_args = list(id = FALSE))
library(rpart)
library(partykit)
pima_rpart <- rpart(type ~ age + bmi + npreg + skin + bp, data = Pima.tr, control = rpart.control(minsplit=10))
plot(as.party(Pima.tr_rpart), tp_args = list(id = FALSE))
pima_rpart <- rpart(type ~ age + bmi + npreg + skin + bp, data = Pima.tr, control = rpart.control(minsplit=10))
plot(as.party(pima_rpart), tp_args = list(id = FALSE))
pima_rpart$cptable
pima_opt <- which.min(pima_rpart$cptable[, "xerror"])
pima_cpval <- pima_rpart$cptable[pima_opt, "CP"]
pima_cpval <- pima_rpart$cptable[pima_opt, "CP"] # Identifies tree with minimized prediction error.
pima_prune <- prune(pima_rpart, cp = pima_cpval) # Prunes data tree.
plot(as.party(pima_prune), tp_args = list(id = FALSE)) # Plots pruned data tree.
test_pred <- predict(pima_prune, newdata = Pima.tr)
xlim <- range(Pima.tr$test)
plot(test_pred ~ test, data = Pima.tr, xlab="Observed", ylab="Predicted", ylim=xlim, xlim=xlim)
abline(a=0, b=1)
library(TH.data)
xlim <- range(Pima.tr$test)
plot(test_pred ~ test, data = Pima.tr, xlab="Observed", ylab="Predicted", ylim=xlim, xlim=xlim)
abline(a=0, b=1)
head(Pima.tr)
type_pred <- predict(pima_prune, newdata = Pima.tr)
xlim <- range(Pima.tr$type)
plot(type_pred ~ type, data = Pima.tr, xlab="Observed", ylab="Predicted", ylim=xlim, xlim=xlim)
abline(a=0, b=1)
xlim <- range(Pima.tr$type)
plot(type_pred ~ type, data = Pima.tr, xlab="Observed", ylab="Predicted")
abline(a=0, b=1)
type_pred <- predict(pima_prune, newdata = Pima.tr)
xlim <- range(Pima.tr$type)
plot(type_pred ~ type, data = Pima.tr, xlab="Observed", ylab="Predicted", ylim=xlim, xlim=xlim)
abline(a=0, b=1)
abline(a=1, b=1)
plot(type_pred ~ type, Pima.tr, log="xy")
plot(type_pred ~ type, data = Pima.tr, xlab="Observed", ylab="Predicted", ylim=xlim, xlim=xlim)
plot(type_pred ~ type, data = Pima.tr, xlab="Observed", ylab="Predicted")
type_pred <- predict(pima_prune, newdata = Pima.tr)
View(test_pred)
type_pred <- predict(pima_prune, newdata = Pima.tr)
xlim <- range(Pima.tr$type)
plot(type_pred ~ type, data = Pima.tr, xlab="Observed", ylab="Predicted", ylim=xlim, xlim=xlim)
abline(a=0, b=1)
xlim <- Pima.tr$type
plot(type_pred ~ type, data = Pima.tr, xlab="Observed", ylab="Predicted", ylim=xlim, xlim=xlim)
abline(a=0, b=1)
plot(type_pred ~ type, data = Pima.tr, xlab="Observed", ylab="Predicted", ylim=2, 2)
abline(a=0, b=1)
plot(type_pred ~ type, data = Pima.tr, xlab="Observed", ylab="Predicted", ylim=2, xlim=2)
plot(type_pred ~ DEXfat, data = Pima.tr, xlab="Observed", ylab="Predicted")
plot(type_pred ~ type, data = Pima.tr, xlab="Observed", ylab="Predicted")
?bodyfat
bodyfat_rpart <- rpart(DEXfat ~ age + waistcirc + hipcirc + elbowbreadth + kneebreadth, data = bodyfat, control = rpart.control(minsplit=10))
plot(as.party(bodyfat_rpart), tp_args = list(id = FALSE))
bodyfat_rpart$cptable
opt <- which.min(bodyfat_rpart$cptable[, "xerror"])
cpval <- bodyfat_rpart$cptable[opt, "CP"]
bodyfat_prune <- prune(bodyfat_rpart, cp = cpval)
plot(as.party(bodyfat_prune), tp_args = list(id = FALSE))
plot(as.party(bodyfat_prune), tp_args = list(id = FALSE))
DEXfat_pred <- predict(bodyfat_prune, newdata = bodyfat)
xlim <- range(bodyfat$DEXfat)
plot(DEXfat_pred ~ DEXfat, data = bodyfat, xlab="Observed", ylab="Predicted", ylim=xlim, xlim=xlim)
abline(a=0, b=1)
library(MASS)
?cpus
cpus.cont <- cpus[,2:8]
cpu_rpart <- rpart(perf ~ ., data = cpus.cont, control = rpart.control(minsplit=10))
plot(as.party(cpu_rpart), tp_args = list(id = FALSE))
cpu_rpart$cptable
# no pruning necessary
## Generating predicted values
cpu_pred <- predict(cpu_rpart, newdata = cpus.cont)
# Compare to observed, and to published predicted values
cpus.cp <- cbind(cpus.cont, cpu_pred)
cpus.cp <- cbind(cpus.cp, cpus$estperf)
plot(cpu_pred ~ perf, cpus.cp, log="xy")
plot(cpu_pred ~ cpus$estperf, cpus.cp, log="xy")
plot(type_pred ~ type, Pima.tr, log="xy")
type_pred <- predict(pima_rpart, newdata = Pima.tr)
View(type_pred)
View(cpus.cont)
head(Pima.tr)
type_pred <- predict(pima_prune, newdata = Pima.tr)
View(type_pred)
?predict
pima_cpval <- pima_rpart$cptable[pima_opt, "CP"] # Identifies tree with minimized prediction error.
pima_prune <- prune(pima_rpart, cp = pima_cpval) # Prunes data tree.
plot(as.party(pima_prune), tp_args = list(id = FALSE)) # Plots pruned data tree.
glaucoma_ctree <- ctree(Class ~ ., data = GlaucomaM)
glaucoma_ctree
plot(glaucoma_ctree, tp_args = list(id = FALSE))
glaucoma_cpred <- predict(glaucoma_ctree, newdata = GlaucomaM)
addpred <- cbind(GlaucomaM, glaucoma_cpred)
table(addpred$Class, addpred$glaucoma_cpred)
Pima_addpred <- cbind(Pima.tr, type_pred)
View(Pima_addpred)
table(addpred$type, addpred$type_pred)
head(GlaucomaM)
nsplitopt <- vector(mode="integer", length=25)
for (i in 1:length(nsplitopt)) {
cp <- rpart(Class ~ ., data=GlaucomaM)$cptable
nsplitopt[i] <- cp[which.min(cp[,"xerror"]), "nsplit"]
}
table(nsplitopt)
trees <- vector(mode="list", length=25)
View(trees)
trees <- vector(mode="list", length=25)
n <- nrow(Pima.tr)
bootsamples <- rmultinom(length(trees), n, rep(1,n)/n)
mod <- rpart(type ~ ., data=Pima.tr, control=rpart.control(xval=0))
for (i in 1:length(trees))
trees[[i]] <- update(mod, weights=bootsamples[,i])
table(sapply(trees, function(x) as.character(x$frame$var[1])))
View(trees)
## Demonstrates "bagging"
trees <- vector(mode="list", length=25)
n <- nrow(Pima.tr)
bootsamples <- rmultinom(length(trees), n, rep(1,n)/n)
mod <- rpart(type ~ ., data=Pima.tr, control=rpart.control(xval=0))
for (i in 1:length(trees))
trees[[i]] <- update(mod, weights=bootsamples[,i])
table(sapply(trees, function(x) as.character(x$frame$var[1])))
## Estimate the conditional probability of glaucoma, given covariates for each person in dataset
classprob <- matrix(0, nrow=n, ncol=length(trees))
for (i in 1:length(trees)) {
classprob[,i] <- predict(trees[[i]], newdata=Pima.tr)[,1]
classprob[bootsamples[,i] > 0, i] <- NA
}
## Average the estimates and assign "glaucoma" when the average probability is more than half
avg <- rowMeans(classprob, na.rm = TRUE)
predictions <- factor(ifelse(avg > 0.5, "diabetes", "normal"))
predtab <- table(predictions, Pima.tr$type)
predtab
glaucoma_cpred <- predict(glaucoma_ctree, newdata = GlaucomaM)
addpred <- cbind(GlaucomaM, glaucoma_cpred)
table(addpred$Class, addpred$glaucoma_cpred)
diabetes_ctree <- ctree(type ~ ., data = Pima.tr)
diabetes_ctree
plot(diabetes_ctree, tp_args = list(id = FALSE))
diabetes_cpred <- predict(diabetes_ctree, newdata = Pima.tr)
addpred <- cbind(Pima.tr, diabetes_cpred)
table(addpred$test, addpred$diabetes_cpred)
## Demonstrates "bagging"
trees <- vector(mode="list", length=200)
n <- nrow(Pima.tr)
bootsamples <- rmultinom(length(trees), n, rep(1,n)/n)
mod <- rpart(type ~ ., data=Pima.tr, control=rpart.control(xval=0))
for (i in 1:length(trees))
trees[[i]] <- update(mod, weights=bootsamples[,i])
table(sapply(trees, function(x) as.character(x$frame$var[1])))
## Estimate the conditional probability of glaucoma, given covariates for each person in dataset
classprob <- matrix(0, nrow=n, ncol=length(trees))
for (i in 1:length(trees)) {
classprob[,i] <- predict(trees[[i]], newdata=Pima.tr)[,1]
classprob[bootsamples[,i] > 0, i] <- NA
}
## Average the estimates and assign "glaucoma" when the average probability is more than half
avg <- rowMeans(classprob, na.rm = TRUE)
predictions <- factor(ifelse(avg > 0.5, "diabetes", "normal"))
predtab <- table(predictions, Pima.tr$type)
predtab
## Conditional inference tree for glaucoma data
diabetes_ctree <- ctree(type ~ ., data = Pima.tr)
diabetes_ctree
plot(diabetes_ctree, tp_args = list(id = FALSE))
diabetes_cpred <- predict(diabetes_ctree, newdata = Pima.tr)
addpred <- cbind(Pima.tr, diabetes_cpred)
table(addpred$test, addpred$diabetes_cpred)
View(test_pred)
## Demonstrates that the solution is not stable
nsplitopt <- vector(mode="integer", length=25)
for (i in 1:length(nsplitopt)) {
cp <- rpart(Class ~ ., data=GlaucomaM)$cptable
nsplitopt[i] <- cp[which.min(cp[,"xerror"]), "nsplit"]
}
table(nsplitopt)
?GlaucomaM
nsplitopt <- vector(mode="integer", length=25)
for (i in 1:length(nsplitopt)) {
cp <- rpart(test ~ age + bmi + npreg + skin + bp, data=Pima.tr)$cptable
nsplitopt[i] <- cp[which.min(cp[,"xerror"]), "nsplit"]
}
table(nsplitopt)
nsplitopt <- vector(mode="integer", length=25)
for (i in 1:length(nsplitopt)) {
cp <- rpart(type ~ age + bmi + npreg + skin + bp, data=Pima.tr)$cptable
nsplitopt[i] <- cp[which.min(cp[,"xerror"]), "nsplit"]
}
table(nsplitopt)
trees <- vector(mode="list", length=25)
n <- nrow(Pima.tr)
bootsamples <- rmultinom(length(trees), n, rep(1,n)/n)
mod <- rpart(type ~ age + bmi + npreg + skin + bp, data=Pima.tr, control=rpart.control(xval=0))
for (i in 1:length(trees))
trees[[i]] <- update(mod, weights=bootsamples[,i])
table(sapply(trees, function(x) as.character(x$frame$var[1])))
## Demonstrates that the solution is not stable
nsplitopt <- vector(mode="integer", length=25)
for (i in 1:length(nsplitopt)) {
cp <- rpart(Class ~ ., data=GlaucomaM)$cptable
nsplitopt[i] <- cp[which.min(cp[,"xerror"]), "nsplit"]
}
table(nsplitopt)
## Demonstrates "bagging"
trees <- vector(mode="list", length=25)
n <- nrow(GlaucomaM)
bootsamples <- rmultinom(length(trees), n, rep(1,n)/n)
mod <- rpart(Class ~ ., data=GlaucomaM, control=rpart.control(xval=0))
for (i in 1:length(trees))
trees[[i]] <- update(mod, weights=bootsamples[,i])
table(sapply(trees, function(x) as.character(x$frame$var[1])))
## Demonstrates that the solution is not stable
nsplitopt <- vector(mode="integer", length=25)
for (i in 1:length(nsplitopt)) {
cp <- rpart(type ~ age + bmi + npreg + skin + bp, data=Pima.tr)$cptable
nsplitopt[i] <- cp[which.min(cp[,"xerror"]), "nsplit"]
}
table(nsplitopt)
## Demonstrates "bagging"
trees <- vector(mode="list", length=25)
n <- nrow(Pima.tr)
bootsamples <- rmultinom(length(trees), n, rep(1,n)/n)
mod <- rpart(type ~ age + bmi + npreg + skin + bp, data=Pima.tr, control=rpart.control(xval=0))
for (i in 1:length(trees))
trees[[i]] <- update(mod, weights=bootsamples[,i])
table(sapply(trees, function(x) as.character(x$frame$var[1])))
classprob <- matrix(0, nrow=n, ncol=length(trees))
for (i in 1:length(trees)) {
classprob[,i] <- predict(trees[[i]], newdata=Pima.tr)[,1]
classprob[bootsamples[,i] > 0, i] <- NA
}
typeprob <- matrix(0, nrow=n, ncol=length(trees))
for (i in 1:length(trees)) {
typeprob[,i] <- predict(trees[[i]], newdata=Pima.tr)[,1]
typeprob[bootsamples[,i] > 0, i] <- NA
}
View(typeprob)
trees <- vector(mode="list", length=25)
n <- nrow(GlaucomaM)
bootsamples <- rmultinom(length(trees), n, rep(1,n)/n)
mod <- rpart(Class ~ ., data=GlaucomaM, control=rpart.control(xval=0))
for (i in 1:length(trees))
trees[[i]] <- update(mod, weights=bootsamples[,i])
table(sapply(trees, function(x) as.character(x$frame$var[1])))
# variable "varg" is selected most of the time
## Estimate the conditional probability of glaucoma, given covariates for each person in dataset
classprob <- matrix(0, nrow=n, ncol=length(trees))
for (i in 1:length(trees)) {
classprob[,i] <- predict(trees[[i]], newdata=GlaucomaM)[,1]
classprob[bootsamples[,i] > 0, i] <- NA
}
View(classprob)
## Average the estimates and assign "diabetes" when the average probability is more than half
avg <- rowMeans(typeprob, na.rm = TRUE)
predictions <- factor(ifelse(avg > 0.5, "diabetes", "normal"))
predtab <- table(predictions, Pima.tr$type)
predtab
round(predtab[1,1]/colSums(predtab)[1]*100)
round(predtab[2,2]/colSums(predtab)[2]*100)
diabetes_ctree <- ctree(type ~ age + bmi + npreg + skin + bp, data = Pima.tr)
diabetes_ctree
plot(diabetes_ctree, tp_args = list(id = FALSE))
}
# does this do any better at prediction?
diabetes_cpred <- predict(diabetes_ctree, newdata = Pima.tr)
addpred <- cbind(Pima.tr, diabetes_cpred)
table(addpred$type, addpred$diabetes_cpred)
avg <- rowMeans(typeprob, na.rm = TRUE)
predictions <- factor(ifelse(avg > 0.5, "diabetes", "normal"))
predtab <- table(predictions, Pima.tr$type)
predtab
avg <- rowMeans(typeprob, na.rm = TRUE)
predictions <- factor(ifelse(avg > 0.5, "diabetes (Yes)", "normal (No)"))
predtab <- table(predictions, Pima.tr$type)
predtab
avg <- rowMeans(typeprob, na.rm = TRUE)
predictions <- factor(ifelse(avg > 0.5, "Yes", "No"))
predtab <- table(predictions, Pima.tr$type)
predtab
round(predtab[1,1]/colSums(predtab)[1]*100)
round(predtab[2,2]/colSums(predtab)[2]*100)
avg <- rowMeans(typeprob, na.rm = TRUE)
predictions <- factor(ifelse(avg > 0.5, "Yes", "No"))
predtab <- table(predictions, Pima.tr$type)
predtab
cpval <- bodyfat_rpart$cptable[opt, "CP"]
bodyfat_prune <- prune(bodyfat_rpart, cp = cpval)
plot(as.party(bodyfat_prune), tp_args = list(id = FALSE))
DEXfat_pred <- predict(bodyfat_prune, newdata = bodyfat)
xlim <- range(bodyfat$DEXfat)
plot(DEXfat_pred ~ DEXfat, data = bodyfat, xlab="Observed", ylab="Predicted", ylim=xlim, xlim=xlim)
abline(a=0, b=1)
avg <- rowMeans(typeprob, na.rm = TRUE)
predictions <- factor(ifelse(avg > 0.5, "Yes", "No"))
predtab <- table(predictions, Pima.tr$type)
predtab
typeprob <- matrix(0, nrow=n, ncol=length(trees))
for (i in 1:length(trees)) {
typeprob[,i] <- predict(trees[[i]], newdata=Pima.tr)[,1]
typeprob[bootsamples[,i] > 0, i] <- NA
}
trees <- vector(mode="list", length=25)
n <- nrow(Pima.tr)
bootsamples <- rmultinom(length(trees), n, rep(1,n)/n)
mod <- rpart(type ~ age + bmi + npreg + skin + bp, data=Pima.tr, control=rpart.control(xval=0))
for (i in 1:length(trees))
trees[[i]] <- update(mod, weights=bootsamples[,i])
table(sapply(trees, function(x) as.character(x$frame$var[1])))
## Estimate the conditional probability of diabetes, given covariates for each person in dataset
typeprob <- matrix(0, nrow=n, ncol=length(trees))
for (i in 1:length(trees)) {
typeprob[,i] <- predict(trees[[i]], newdata=Pima.tr)[,1]
typeprob[bootsamples[,i] > 0, i] <- NA
}
library(HSAUR3)
library(coin)
library(dplyr)
library(survival)
?lung
plot(survfit(Surv(time, status) ~ 1, data=lung), xlab="Days", ylab="Overall Survival Probability")
?glioma
head(glioma)
summary(glioma)
survfit(Surv(time, event) ~ group, data=glioma)
plot(survfit(Surv(time, event) ~ group, data=glioma), ylab="Probability", xlab="Survival Time (Months)", lty=c(2,1))
summary(coxph(Surv(time, event) ~ group, data=glioma))
library(HSAUR3)
library(coin)
library(dplyr)
library(survival)
?lung
head(lung)
?diabetic
head(diabetic)
plot(survfit(Surv(time, status) ~ 1, data=diabetic), xlab="Days", ylab="Visual Status")
?Diabetic
?diabetic
?diabetic
survfit(Surv(time, status) ~ 1, data=diabetic)
?lung
diabetic
survfit(Surv(time, status) ~ 1, data=diabetic)
plot(survfit(Surv(time, status) ~ 1, data=diabetic), xlab="Days", ylab="Visual Status")
plot(survfit(Surv(time, status) ~ 1, data=diabetic), xlab="Months", ylab="Visual Status")
survfit(Surv(time, status) ~ 1, data=lung)
plot(survfit(Surv(time, status) ~ 1, data=lung), xlab="Days", ylab="Overall Survival Probability")
plot(survfit(Surv(time, status) ~ sex, data=lung), xlab="Days", ylab="Overall Survival Probability", lty=c(1,2))
plot(survfit(Surv(time, status) ~ laser, data=diabetic), xlab="Months", ylab="Visual Status")
plot(survfit(Surv(time, status) ~ laser, data=diabetic), xlab="Months", ylab="Visual Status", lty=c(1,2))
plot(survfit(Surv(time, status) ~ laser, data=diabetic), xlab="Months", ylab="Visual Status", lty=c(argon,xenon))
plot(survfit(Surv(time, status) ~ laser, data=diabetic), xlab="Months", ylab="Visual Status", lty=c(1,2))
plot(survfit(Surv(time, status) ~ laser, data=diabetic), xlab="Months", ylab="Visual Status")
plot(survfit(Surv(time, status) ~ laser, data=diabetic), xlab="Months", ylab="Visual Status", lty=c(1,2))
plot(survfit(Surv(time, status) ~ laser, data=diabetic), xlab="Months", ylab="Overall Non-Blindless Probability", lty=c(1,2))
survfit(Surv(time, status) ~ laser, data=diabetic)
survfit(Surv(time, status) ~ laser, data=diabetic
?diabetic
?diabetic
?diabetic
